{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analytics = AI + ML + DL + tools used for creating value from data.\n",
    "- AI = Systems and algos that exhibit human-like intelligence.\n",
    "- ML = Subset of AI, comprises of using statistical algos to extract intelligence from big data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ML : It gives computer ability to learn without being explicitly programmed.\n",
    "- model = simplified representation of reality created to serve some purpose.\n",
    "- A prediction model is a formula for estimating the unknown value of interest: **the target**.\n",
    "- In data science, prediction more generally means to estimate an unknown value.\n",
    "- Indeed, since data mining techniques involves collecting huge amounts of historical data.\n",
    "- Models are very often are built and tested using events from the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "                               transduction\n",
    "                        data -----------------> prediction\n",
    "                        |                           ^    \n",
    "                        |                           |\n",
    "            induction   |                           |\n",
    "                        |                           | deduction\n",
    "                        |                           |\n",
    "                        V                           |\n",
    "                        model ----------------------|\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro:\n",
    "- AI is a discipline\n",
    "- ML is a subfield of AI\n",
    "- DL is a subfield of ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of ML algorithms:\n",
    "- Supervised\n",
    "- Unsupervised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if y = x -> Unsupervised learning\n",
    "- if y = {0, 1} -> Supervised **binary classification**\n",
    "- if y = {0, 1, ...} -> Supervised **multiclass classification**\n",
    "- if y = {-inf, inf} -> Supervised **regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised ML algorithms:\n",
    "- require the knowledge of both outcome varaible (dependent variable) and the features (independent variable).\n",
    "- usually a **loss function** is required.\n",
    "- eg: linear regression and logistic regression.\n",
    "- ps: logistic regression is just another name for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- amount of data points in y is very important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised ML algorithms:\n",
    "- No knowledge of outcome variable is given to the algorithms.\n",
    "- Algorithms must find the possible values of the outcome variable.\n",
    "- Examples: clustering, principal component analysis, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- principal component analysis = It helps to reduce the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML algorithms:\n",
    "- For supervised learning:\n",
    "<pre>\n",
    "input data -> Model < ----------------\n",
    "                |                     | Model update\n",
    "                V                     |\n",
    "            predict output -------> Error (Loss function)\n",
    "                |             ^\n",
    "        Compare |             |\n",
    "                V             |\n",
    "            Expected output --|\n",
    "</pre>\n",
    "\n",
    "- For unsupervised learning:\n",
    "<pre>\n",
    "\n",
    "    input data -> model -> generated example\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why ML?\n",
    "- It helps in understanding the association between key performance indicators (KPIs).\n",
    "- Identifying the factors that have a significant impact on the KPIs for effective management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in ML:\n",
    "1. Identify the problem or opportunity for value creation.\n",
    "2. Identify sources of data and create a data lake.\n",
    "3. Pre-process the data for issues such as missing and incorrect data.\n",
    "4. Generate derived variables and transform the data if necessary.\n",
    "5. Divide the datasets into subsets of training and validation datasets.\n",
    "6. Build ML models to identify the best model(s) using model performance in validation data.\n",
    "7. Implement Solution/Decision/Develop Product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are two phases, first phase is training and second phase is validation.\n",
    "- in training, we simply train the model with largest section of data available.\n",
    "- in validation, we do the same, but with a different section of data and this data is distinct from training data.\n",
    "- the purpose of validation, is to ensure that training has happened properly.\n",
    "- Instructor gives the following example:\n",
    "    - Training is like securing marks in internal exam.\n",
    "    - Validation is like securing marks in final exam.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The main goal is to minimize the loss function,\n",
    "- Instructor draws a parabola, x = loss function, y = complexity of ML.\n",
    "- This is curve is called \"loss function vs complexity of ML model\"\n",
    "- left hand of parabola is **Low variance and high bias**\n",
    "- right hand of parabola is **low bias and high variance**\n",
    "- The global minima of the curve is **moderate bias and moderate variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised machine learning algorithms:\n",
    "- Objective is to generate labels.\n",
    "- How many groups are required to make the data clusters which can be labelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using distance measures such as Euclidean distance in clustering\n",
    "- Learn to build clusters using sklearn library in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction unsupervised learning (ML)\n",
    "- Training data = X = {x1, x2, ..., xn}, X âŠ‚ R<sup>n</sup>\n",
    "- Clustering / segmentation: \n",
    "    - f : R<sup>d</sup> ---> {C1, ..., Ck} (set of clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to clustering\n",
    "- Clustering is a divide-and-conquer strategy which divides the dataset into homogenous groups which can be further used to prescribe the right strategy for different groups.\n",
    "- In clustering, **the objective** is to ensure that the **variation within a cluster is minimized while the variation between clusters is maximized**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study: Do clustering operation on customer data.\n",
    "- Establish a relationship between age and salary with k-mean clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading data:\n",
    "```python\n",
    "    import pandas as pd\n",
    "    customers_df = pd.read_csv(\"customers.csv\")\n",
    "    customers_df.head(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider grouping as per their income:\n",
    "    - Low income with low age\n",
    "    - Medium income with medium age\n",
    "    - High income with high age etc...\n",
    "- For this problem statement there can be 4 possibilities for (age,income) pairings:\n",
    "    - LL, LH, HL, HH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizing the relationship:\n",
    "```python\n",
    "    # Visualize them before going for clustering\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sn\n",
    "    %matplotlib inline\n",
    "\n",
    "    sn.lmplot(data=customers_df, x='age', y = 'income');\n",
    "    plt.title(\"Fig 1: Customer segments based on income and age\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similarities using distance:\n",
    "- Clustering techniques assume that there are subsets in the data that are similar or homogeneous.\n",
    "- One approach for measuring similarity is through distance measured using different metrics.\n",
    "- Few distance measures used in clustering are discussed in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance\n",
    "- D(X1, X2) = sqrt(  Summation_of( (Xi1 - Xi2)^2 )  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other methods of distance measurement:\n",
    "- minkowski distance\n",
    "- jaccard similarity coefficent\n",
    "- cosine similarity\n",
    "- gower's similarity coefficent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedurre of k-mean clustering (All of this happens internally):\n",
    "1. Decide the value of k.\n",
    "2. Choose K observations from the data that are likely to be in different clusters. choose observations that are farthest.\n",
    "3. The K observations selected in step 2 are the centroids of those clusters.\n",
    "4. For remaining observations, find the cluster closest to the centroid. Add the new observation (say observation j) to the cluster with the closest centroid. Adjust the centroid after adding a new observation to the cluster. The closest centroid is chosen based upon an appropriate distance measure.\n",
    "5. Repeat step 4 until all observations are assigned to a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Question for understanding the iterations of K-means clustering: \n",
    "- Given 5 points and 2 centroids C1 = (4,2), C2 = (3,5). (See pic for 5 points)\n",
    "    1. Find the new two Centroid points after first iteration.\n",
    "        - Solution: \n",
    "        - C1 = [(5,3), (3,1)]\n",
    "        - C2 = [(2,5), (1,5), (4,4)]\n",
    "        - C1new = ( (5+3)/2, (3+1)/2 ) = (4,2)\n",
    "        - C2new = ( (2+1+4)/3, (5+5+4)/3 ) = (2.33, 4.66)\n",
    "        - This is the end of first iteration.\n",
    "        - Note that these iterations continue on until no change in centroid points are seen.\n",
    "\n",
    "    2. Find the new two centroid points after second iteration.\n",
    "        - Solution:\n",
    "        - C1 = [(5,3), (3,1)]\n",
    "        - C2 = [(2,5), (1,5), (4,4)]\n",
    "        - C1new = ( (5+3)/2, (3+1)/2 ) = (4,2)\n",
    "        - C2new = ( (2+1+4)/3, (5+5+4)/3 ) = (2.33, 4.66)\n",
    "        - This is the end of first iteration.\n",
    "        - Note that there was no change in centroid points.\n",
    "        - This means we will stop the iteration here itself.\n",
    "        - These are the final coordinates of the two centroids:\n",
    "        - C1 = (4,2)\n",
    "        - C2 = (2.33, 4.66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method of finding exact number of clusters:\n",
    "- Although the number of clusters is often arbitrary.\n",
    "- But there is a procedure to find teh optimal number.\n",
    "- Eg: Elbow method and WCSS (Within Cluster Sums of Square)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method of finding exact number of clusters...\n",
    "```python\n",
    "\n",
    "# Using Elbow method and WCSS finding optimum no. of clusters:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(customers_df)\n",
    "    # kmeans.inertia_ = Sum of squared distances of samples to their closest cluster center, weighted by the sample weights if provided.\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    plt.plot(wcss)\n",
    "    plt.title('The Elbow method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating empty cluster: From above test k can be selected as 3, and labels to it\n",
    "```python\n",
    "\n",
    "    # figure shows that k=3\n",
    "    from sklearn.cluster import KMeans\n",
    "    clusters = KMeans(3)\n",
    "    clusters.fit(customers_df)\n",
    "\n",
    "    # Now create a label for the data\n",
    "    customers_df[\"clusterid\"] = clusters.labels_\n",
    "\n",
    "    # display the sample data\n",
    "    customers_df[0:5]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Customers with their Segments:\n",
    "```python\n",
    "    # Plotting the customers with their segments\n",
    "    sn.lmplot( data=customers_df, x=\"age\", y=\"income\", hue=\"clusterid\" )\n",
    "    plt.title(\"Fig 2: Customer Segments Based on Income and Age with clusterid\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the same with normalization of feature:\n",
    "- If we observe the two features income and age, we see a large amount of variation between their respective ranges.\n",
    "- eg: age range is 18 to 70, whereas income range is 1 lakh to 9 lakh.\n",
    "- The gap in the two ranges are huge, which may effect the model preparation.\n",
    "- To treat them equally we need to do scaling of features.\n",
    "- Here we do **normalization of features**.\n",
    "- By creating a same scale for both features, doing more operations on them becomes more convienent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the same without normailization of feature\n",
    "\n",
    "```python\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_customers_df = scaler.fit_transform(customers_df[[\"age\", \"income\"]])\n",
    "    scaled_customers_df[0:5]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Clusters using normalized feature set:\n",
    "```python\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    clusters_new = KMeans(3, random_state=42)\n",
    "    clusters_new.fit(scaled_customers_df)\n",
    "    customers_df[\"clusterid_new\"] = clusters_new.labels_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot after normalization:\n",
    "```python\n",
    "\n",
    "    # Plotting the customers with their segments:\n",
    "    sn.lmplot( data=customers_df, x=\"age\", y=\"income\", hue=\"clusterid_new\" )\n",
    "    plt.title( \"Fig 3: Customer Segments Based on Income and Age with clusterid_new\" )  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Also see the lab task: \"kmeans.ipynb\" for all the code and plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
