{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPGPU Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPU Overview.\n",
    "- eg: Intel arc pro, AMD Radeon pro, Nvidia Tesla.\n",
    "- CPU has low throughput incase of computer intensive tasks.\n",
    "- CPU are slower with enhancing images and rendering graphics.\n",
    "- GPUs outdo CPUs when it comes to 3D rendering due to the complexity of the tasks.\n",
    "- GPU cores are specialized processors for handling graphics manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## GPU v/s CPU\n",
    "- Parallelism\n",
    "- Instruction set Architecture\n",
    "- Memory Hierarchy\n",
    "- Floating-Point Performance\n",
    "- Power Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Key Milestones in Evolution:\n",
    "- Graphics Rendering\n",
    "- Programmability\n",
    "- General-Purpose Computing\n",
    "- CUDA and GPGPU\n",
    "- GPU Libraries and Frameworks:\n",
    "    - cuDNN (CUDA Deep Neural Network),\n",
    "    - TensorRT,\n",
    "    - CUDA Toolkit\n",
    "- AI and Deep Learning\n",
    "- Heterogeneous Computing.\n",
    "- Heterogeneous Co-processing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## GP-GPU Overview\n",
    "- General Purpose GPU or GPGPU - general purpose scientific and engineering computing.\n",
    "- refer slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Applications:\n",
    "- Big data processing\n",
    "- Machine Learning and AI\n",
    "- Scientific simulations\n",
    "- Virtual reality and gaming\n",
    "- Cryptography and cyber security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Performance\n",
    "- refer slides with info from Nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Outline of GP-GPU\n",
    "- Peripheral component Interface express bus (PCI-express bus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand GP-GPU Architecture\n",
    "- At typical GP-GPU architectre consists of the following components:\n",
    "- GPU core\n",
    "- Instruction cache.\n",
    "- Texture units\n",
    "- Interconnect network\n",
    "- Streaming multiprocessors\n",
    "- Data Processing Unit\n",
    "- Load/Store Unit\n",
    "- Special Function Unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nvidia tesla v100 archeitecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Architecture of SM and execution model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Memory Structure:\n",
    "- Thread registers\n",
    "- Thread local memory\n",
    "- block shared memory\n",
    "- grid global memory\n",
    "- grid constant memory\n",
    "- grid texture memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming models for GPGPU\n",
    "- Low level \n",
    "    - CUDA - Compute Unified Device Architecture\n",
    "    - OpenCL\n",
    "- Directives:\n",
    "    - OpenMP - Open Multi-Processing\n",
    "    - OpenACC - Open Accelerator\n",
    "\n",
    "- In directives = C compiler imports a libraries and directives tell C compiler how to compile and execute\n",
    "- Low level uses a different compiler altogether. There are no directives, the entire code is different and customized for the hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Basic Terms:\n",
    "- Host - The CPU and its memory\n",
    "- Device - The GPU and its memory\n",
    "- Kernel - Function compiled for the device and its executed on the device with many threads\n",
    "- block - a group of threads\n",
    "- grid - a group of blocks\n",
    "- warp - a group of grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Architecture\n",
    "- C code runs serailly on CPU\n",
    "- Parallel execution is expressed by the kernel function that is executed on a set of threads in parallel on GPU.\n",
    "- Returns back to host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCL\n",
    "- lengthy code\n",
    "- refer slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## OpenMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to CUDA\n",
    "- Large similarity to OpenMP directives\n",
    "- works for Fortran, C, and C++\n",
    "- Compilers supported - PGI, CRAY, GCC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Execution Model\n",
    "- Program runs on the host CPU\n",
    "- offload compute-intensive regions (kernels) and related data to accelerator GPU.\n",
    "- Compute Kernels are executed by the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levels of Parallelism\n",
    "1. Gang\n",
    "2. Worker\n",
    "3. Vector (useful for SIMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Key Concepts\n",
    "- Vector: Threads work in SIMD fashion.\n",
    "    - Individual tasks that are executed in parallel on the GPU.\n",
    "    - threads are organized into warps, which are groups of 32 threads each.\n",
    "    - All threads within a warp are executed on a single GPU core.\n",
    "- Worker: Groups of threads that can be scheduled and executed on a streaming multiprocessor (SM) within the GPU.\n",
    "- Gang: workers are organized into gangs. Gangs work independently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## OpenACC Syntax\n",
    "- For C/C++: #pragma acc directive clauses\n",
    "- Fortran: !$acc directive clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling an OpenACC Program:\n",
    "- Compiler that support OpenACC usually require an option that enables the feature:\n",
    "    - PGI: -acc\n",
    "- pgcc --acc --Minfo=all test.c\n",
    "- Minfo=all is a flag that helps display all the debugging info in verbose mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties:\n",
    "- Incremental\n",
    "- Single source\n",
    "- Interoperable\n",
    "- Portable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer constructs:\n",
    "- parallel\n",
    "    - Defines a region to be executed on an accelerator\n",
    "    - Work sharing parallelism has to be defined manually.\n",
    "- kernels\n",
    "    - Defines a region to be transferred into a series of kernels to be executed in sequence on an accelerator\n",
    "    - Work sharing parallelism is defined automatically for the separate kernels.\n",
    "- With similar work sharing, both can perform equally well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Constructs: Kernels\n",
    "- specified by:\n",
    "- #pragma acc kernels [clause [,clause]...] new-line structured block\n",
    "- each iteration of for loop is executed as a separate kernel\n",
    "- each kernel is executed sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Instructor displays a code with 2 for loops one after another\n",
    "- note that like OpenMP, we dont we dont have use kernels for each separate for loop\n",
    "    - in kernel compiler will take care of creating multiple gangs and assign workers and vectors accordingly for each iteration.\n",
    "- however in parallel, we have to specify the directive before each loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Compute construct \n",
    "    - parallel\n",
    "    - kernels\n",
    "    \n",
    "- Loop construct\n",
    "    - loop\n",
    "\n",
    "- There are differences in compiler level between all of these different constructs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work sharing construct: loop\n",
    "- #pragma acc loop [clause [,clause]...] new-line for loop\n",
    "- combined constructs\n",
    "    - #pragma acc kernels loop\n",
    "    - #pragma acc parallel loop\n",
    "- Loop index variables are private variables by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Clauses\n",
    "- refer slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Parallel/kernel clause\n",
    "- if clause\n",
    "- async clause\n",
    "- num_gangs clause\n",
    "- num_workers clause\n",
    "- vector_length clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Private\n",
    "- each loop iteration requires its own copy of its listed variables.\n",
    "- Syntax: private(var1, var2, var3, ...)\n",
    "- Avoids race condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction\n",
    "- Syntax: reduction(operator:variable)\n",
    "- Instructor shows code snipped with and without reduction.\n",
    "- and demonstrates how without reduction, we get wrong output and with reduction we get right output.\n",
    "- the code snippet is about parallelising a sum of an array which contains an AP with a = 1, d = 1, and last_n = 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clauses for Data directive\n",
    "- if(condition)\n",
    "- copy(list)\n",
    "- copyin(list)\n",
    "- copyout(list)\n",
    "- create(list)\n",
    "- present(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "-  Instructor presents a code snipped with copypin, copyout, and present directives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shaping of arrays:\n",
    "- array slicing in OpenAcc.\n",
    "- Syntax: x[start:count]\n",
    "    - x = variable name\n",
    "    - start = start index\n",
    "    - count = total number of elements to be selected from start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Summary of OpenACC Directives:\n",
    "```C++\n",
    "// Manage data movement:\n",
    "#pragma acc data copyin(a,b) copyout(c)\n",
    "{\n",
    "    ...\n",
    "    // Initiate parallel execution:\n",
    "    #pragma acc parallel\n",
    "    {\n",
    "        // Optimize Loop Mappings:\n",
    "        #pragma acc loop gang vector\n",
    "            for(i=0; i<n; ++i){\n",
    "                c[i] = a[i] + b[i];\n",
    "                ...\n",
    "            }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab session on writing OpenACC on PARAM Utkarsh:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now instructor suggests to copy all the code from a specific directory by using the following command:\n",
    "```bash\n",
    "    cp -r /tmp/CBP/ ~/GPGPU\n",
    "```\n",
    "- then go to h_openacc folder, find the kernel.c file and run the above commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use the following command to compile:\n",
    "```bash\n",
    "    pgcc -acc -Minfo=all -ta=tesla:cc70 kernel.c\n",
    "```\n",
    "- If you try to compile, it will show that pgcc: command not found...\n",
    "- therefore we need to load the module first.\n",
    "- use the following command to see available modules: \n",
    "```bash\n",
    "    module avail | grep compiler\n",
    "```\n",
    "- load this specific module: \"compiler/hpc_sdk/nvhpc/21.7\"\n",
    "- in order to load the module run this command:\n",
    "```bash\n",
    "    module load compiler/hpc_sdk/nvhpc/21.7\n",
    "```\n",
    "- Then compile using this:\n",
    "```bash\n",
    "    pgcc -acc -Minfo=all -ta=tesla:cc70 kernel.c\n",
    "```\n",
    "- then edit the slurm file called \"run_gpu.sh\" to include the object file that was generated.\n",
    "- Instructor did not specify the object name, so in slurm file you will see \"./a.out\" which is the default object file name\n",
    "- then use the following command to submit the job:\n",
    "```bash\n",
    "    sbatch run_gpu.sh\n",
    "```\n",
    "- check the status of your job using:\n",
    "```bash\n",
    "    squeue | grep insert_job_id_here\n",
    "```\n",
    "- Or you can also use:\n",
    "```bash\n",
    "    squeue -u insert_username_here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Executing code with parallel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now compile and execute \"parallel.c\"\n",
    "```bash\n",
    "    pgcc -acc -Minfo=accel -ta=tesla:cc70 parallel.c\n",
    "```\n",
    "- here -Minfo=accel gives us debug info about the accelerator only\n",
    "- also -ta is the \"target accelerator\", here we are using Nvidia's tesla GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing matrix multiplication\n",
    "- Param utkarsh stops responding.\n",
    "- instructor shows how to execute matrixMultiply.c file.\n",
    "- we get a segfault, this is because stack size was reached\n",
    "- use the following command to get rid of segfault:\n",
    "```bash\n",
    "    ulimit -s unlimited\n",
    "```\n",
    "- then execute using:\n",
    "```bash\n",
    "    time ./a.out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the instructor's explanation for how matrix multiplication happens parallely:\n",
    "- At the Assembly level, threads do read, execute, store.\n",
    "- so lets say that matrix dimensions are NxN, then N threads will be created,\n",
    "- each of these n threads will do parallel multiplication of a specific row of first matrix and specific column of second matrix.\n",
    "- and then iterate and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra learning:\n",
    "- Instructor also shows code on fast-fourier transform and how to execute parallely.\n",
    "- see file \"FFT.c\" to see the code for fast-fourier transform.\n",
    "\n",
    "- For documentation and further learning, Refer to official website: \n",
    "    - www.openacc.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Instructor's final instructions on how to run openacc programs on PARAM Utkarsh:\n",
    "1. Login to your PARAM Utkarsh account.\n",
    "2. Load the module:\n",
    "```bash\n",
    "    module load compiler/hpc_sdk/nvhpc/21.7\n",
    "```\n",
    "copy the codes:\n",
    "```bash\n",
    "    cp -r <source> <destination>\n",
    "    # In PARAM Utkarsh, codes are in CBP folder:\n",
    "    cp -r /tmp/CBP ~\n",
    "```\n",
    "Or Type the code.\n",
    "3. Insert pragmas.\n",
    "4. Compile the code using PGI compiler\n",
    "```bash\n",
    "    pgcc -acc -Minfo=all -ta=tesla:cc70 <filename.c>\n",
    "```\n",
    "5. Submit through slurm\n",
    "```bash\n",
    "    sbatch run_gpu.sh\n",
    "```\n",
    "6. Check whether it is in the queue.\n",
    "```bash\n",
    "    squeue -u <your username>\n",
    "```\n",
    "7. Check the \".out\" & \".err\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In exam, we have to compile in our local system and execute on the Param Utkarsh.\n",
    "- Make sure you include all the directives, clauses and flags properly during exam, even if Param Utkarsh goes offline."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
